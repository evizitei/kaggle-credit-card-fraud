{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud\n",
    "\n",
    "This notebook uses data from kaggle to practice supervised learning on pre-PCA'd data.  The relevant dataset can be found [here](https://www.kaggle.com/dalpozz/creditcardfraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "frame = pd.read_csv(\"./data/creditcard.csv\")\n",
    "frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial impressions\n",
    "\n",
    "The data in this csv doesn't represent recognizable signals from the relevant transactions; each \"V\" is already a PCA vector, and is intentionally provided without the original dataset for confidentiality reasons.  This means I have no way to develop any intuition about what's important just from knowing the domain, which is kind of a neat new challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.165980e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.373150e-15</td>\n",
       "      <td>2.086869e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.490107e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.177556e-16</td>\n",
       "      <td>-2.406455e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.656562e-16</td>\n",
       "      <td>-3.444850e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.471968e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.687098e-15</td>\n",
       "      <td>-3.666453e-16</td>\n",
       "      <td>-1.220404e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.165980e-15  3.416908e-16 -1.373150e-15  2.086869e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   9.604066e-16  1.490107e-15 -5.556467e-16  1.177556e-16 -2.406455e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "           ...                 V21           V22           V23           V24  \\\n",
       "count      ...        2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean       ...        1.656562e-16 -3.444850e-16  2.578648e-16  4.471968e-15   \n",
       "std        ...        7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min        ...       -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%        ...       -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%        ...       -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%        ...        1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max        ...        2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   5.340915e-16  1.687098e-15 -3.666453e-16 -1.220404e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There *are* two columns that are labeled in the dataset, one is time since the interval began for this dataset, and one is the value of the transaction.  Let's take a minute and see if either of them are noticably different from fraudulent to regular transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     492.000000\n",
       "mean      122.211321\n",
       "std       256.683288\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         9.250000\n",
       "75%       105.890000\n",
       "max      2125.870000\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.Amount[frame.Class == 1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    284315.000000\n",
       "mean         88.291022\n",
       "std         250.105092\n",
       "min           0.000000\n",
       "25%           5.650000\n",
       "50%          22.000000\n",
       "75%          77.050000\n",
       "max       25691.160000\n",
       "Name: Amount, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.Amount[frame.Class == 0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For amount, unsurprisingly, there's a lot less range for fraudulent transactions.  I suppose to a fraudster, it feels like large transactions are likely to get noticed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       492.000000\n",
       "mean      80746.806911\n",
       "std       47835.365138\n",
       "min         406.000000\n",
       "25%       41241.500000\n",
       "50%       75568.500000\n",
       "75%      128483.000000\n",
       "max      170348.000000\n",
       "Name: Time, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.Time[frame.Class == 1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    284315.000000\n",
       "mean      94838.202258\n",
       "std       47484.015786\n",
       "min           0.000000\n",
       "25%       54230.000000\n",
       "50%       84711.000000\n",
       "75%      139333.000000\n",
       "max      172792.000000\n",
       "Name: Time, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame.Time[frame.Class == 0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a glance there isn't much interesting here for time. However, the categories are very unbalanced; there are 284,000 valid transactions and just under 500 fraudulent.  It would be very possible in a test train split to accidentally put all the fraud examples in one set or the other.  We should split them and control how many of each go into each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud = frame[frame.Class == 1]\n",
    "valid = frame[frame.Class == 0]\n",
    "len(fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_percentage = 0.85\n",
    "validation_percentage_of_test = 0.3\n",
    "\n",
    "fraud_train = fraud.sample(frac=training_percentage)\n",
    "fraud_train_inverse = fraud.drop(fraud_train.index)\n",
    "fraud_validation = fraud_train_inverse.sample(frac=validation_percentage_of_test)\n",
    "fraud_test = fraud_train_inverse.drop(fraud_validation.index)\n",
    "# oversample the minority class\n",
    "fraud_train = pd.concat([fraud_train, fraud_train, fraud_train, fraud_train])\n",
    "fraud_train = pd.concat([fraud_train, fraud_train, fraud_train, fraud_train])\n",
    "fraud_train = pd.concat([fraud_train, fraud_train, fraud_train, fraud_train])\n",
    "\n",
    "\n",
    "valid_train = valid.sample(frac=training_percentage)\n",
    "valid_train_inverse = valid.drop(valid_train.index)\n",
    "valid_validation = valid_train_inverse.sample(frac=validation_percentage_of_test)\n",
    "valid_test = valid_train_inverse.drop(valid_validation.index)\n",
    "# undersample the majority class\n",
    "valid_train = valid_train.sample(frac=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now they can be concatenated into complete sets and shuffled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "train_features = shuffle(pd.concat([fraud_train, valid_train]))\n",
    "test_features = shuffle(pd.concat([fraud_test, valid_test]))\n",
    "validation_features = shuffle(pd.concat([fraud_validation, valid_validation]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can pull out the labels, and drop them from the feature frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels = train_features.Class\n",
    "test_labels = test_features.Class\n",
    "validation_labels = validation_features.Class\n",
    "train_features = train_features.drop(['Class'], axis=1)\n",
    "test_features = test_features.drop(['Class'], axis=1)\n",
    "validation_features = validation_features.drop(['Class'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>147586.000000</td>\n",
       "      <td>147586.000000</td>\n",
       "      <td>147586.000000</td>\n",
       "      <td>147586.000000</td>\n",
       "      <td>147586.000000</td>\n",
       "      <td>147586.000000</td>\n",
       "      <td>147586.000000</td>\n",
       "      <td>147586.000000</td>\n",
       "      <td>147586.000000</td>\n",
       "      <td>147586.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>147586.000000</td>\n",
       "      <td>147586.000000</td>\n",
       "      <td>147586.000000</td>\n",
       "      <td>147586.000000</td>\n",
       "      <td>147586.000000</td>\n",
       "      <td>147586.000000</td>\n",
       "      <td>147586.000000</td>\n",
       "      <td>147586.000000</td>\n",
       "      <td>147586.000000</td>\n",
       "      <td>147586.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>92083.879081</td>\n",
       "      <td>-0.822654</td>\n",
       "      <td>0.631290</td>\n",
       "      <td>-1.221204</td>\n",
       "      <td>0.805675</td>\n",
       "      <td>-0.526940</td>\n",
       "      <td>-0.253155</td>\n",
       "      <td>-0.957899</td>\n",
       "      <td>0.093502</td>\n",
       "      <td>-0.450655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065634</td>\n",
       "      <td>0.112510</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>-0.010763</td>\n",
       "      <td>-0.019136</td>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.010054</td>\n",
       "      <td>0.029891</td>\n",
       "      <td>0.015904</td>\n",
       "      <td>93.021534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47934.843600</td>\n",
       "      <td>3.806442</td>\n",
       "      <td>2.705999</td>\n",
       "      <td>4.197309</td>\n",
       "      <td>2.456529</td>\n",
       "      <td>2.813501</td>\n",
       "      <td>1.532080</td>\n",
       "      <td>3.825485</td>\n",
       "      <td>3.017389</td>\n",
       "      <td>1.735221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.922374</td>\n",
       "      <td>1.715664</td>\n",
       "      <td>0.900441</td>\n",
       "      <td>0.894272</td>\n",
       "      <td>0.590721</td>\n",
       "      <td>0.580118</td>\n",
       "      <td>0.478784</td>\n",
       "      <td>0.681384</td>\n",
       "      <td>0.376441</td>\n",
       "      <td>248.840715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>-46.855047</td>\n",
       "      <td>-63.344698</td>\n",
       "      <td>-32.965346</td>\n",
       "      <td>-5.519697</td>\n",
       "      <td>-42.147898</td>\n",
       "      <td>-23.496714</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>...</td>\n",
       "      <td>-28.009635</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-30.269720</td>\n",
       "      <td>-2.822684</td>\n",
       "      <td>-7.495741</td>\n",
       "      <td>-2.534330</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-11.710896</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>51426.250000</td>\n",
       "      <td>-1.298443</td>\n",
       "      <td>-0.477496</td>\n",
       "      <td>-1.615401</td>\n",
       "      <td>-0.685276</td>\n",
       "      <td>-0.934655</td>\n",
       "      <td>-0.971244</td>\n",
       "      <td>-0.892838</td>\n",
       "      <td>-0.209479</td>\n",
       "      <td>-1.026896</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206396</td>\n",
       "      <td>-0.215443</td>\n",
       "      <td>-0.545816</td>\n",
       "      <td>-0.182292</td>\n",
       "      <td>-0.372216</td>\n",
       "      <td>-0.317991</td>\n",
       "      <td>-0.314087</td>\n",
       "      <td>-0.069208</td>\n",
       "      <td>-0.054008</td>\n",
       "      <td>3.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>83243.500000</td>\n",
       "      <td>-0.272500</td>\n",
       "      <td>0.250864</td>\n",
       "      <td>-0.168438</td>\n",
       "      <td>0.285916</td>\n",
       "      <td>-0.148289</td>\n",
       "      <td>-0.388440</td>\n",
       "      <td>-0.083415</td>\n",
       "      <td>0.057332</td>\n",
       "      <td>-0.201091</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039046</td>\n",
       "      <td>0.012646</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>-0.016927</td>\n",
       "      <td>0.028828</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>-0.039680</td>\n",
       "      <td>0.014370</td>\n",
       "      <td>0.017171</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>137769.500000</td>\n",
       "      <td>1.233204</td>\n",
       "      <td>1.145381</td>\n",
       "      <td>0.855995</td>\n",
       "      <td>1.384394</td>\n",
       "      <td>0.579607</td>\n",
       "      <td>0.296348</td>\n",
       "      <td>0.493810</td>\n",
       "      <td>0.459822</td>\n",
       "      <td>0.478908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.215385</td>\n",
       "      <td>0.278251</td>\n",
       "      <td>0.539630</td>\n",
       "      <td>0.161528</td>\n",
       "      <td>0.410870</td>\n",
       "      <td>0.368708</td>\n",
       "      <td>0.272505</td>\n",
       "      <td>0.169662</td>\n",
       "      <td>0.111651</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172788.000000</td>\n",
       "      <td>2.454930</td>\n",
       "      <td>22.057729</td>\n",
       "      <td>9.382558</td>\n",
       "      <td>16.715537</td>\n",
       "      <td>34.099309</td>\n",
       "      <td>22.529298</td>\n",
       "      <td>36.877368</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>15.594995</td>\n",
       "      <td>...</td>\n",
       "      <td>39.420904</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>10.503090</td>\n",
       "      <td>19.228169</td>\n",
       "      <td>4.022866</td>\n",
       "      <td>7.519589</td>\n",
       "      <td>3.220178</td>\n",
       "      <td>12.152401</td>\n",
       "      <td>22.620072</td>\n",
       "      <td>19656.530000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time             V1             V2             V3  \\\n",
       "count  147586.000000  147586.000000  147586.000000  147586.000000   \n",
       "mean    92083.879081      -0.822654       0.631290      -1.221204   \n",
       "std     47934.843600       3.806442       2.705999       4.197309   \n",
       "min         2.000000     -46.855047     -63.344698     -32.965346   \n",
       "25%     51426.250000      -1.298443      -0.477496      -1.615401   \n",
       "50%     83243.500000      -0.272500       0.250864      -0.168438   \n",
       "75%    137769.500000       1.233204       1.145381       0.855995   \n",
       "max    172788.000000       2.454930      22.057729       9.382558   \n",
       "\n",
       "                  V4             V5             V6             V7  \\\n",
       "count  147586.000000  147586.000000  147586.000000  147586.000000   \n",
       "mean        0.805675      -0.526940      -0.253155      -0.957899   \n",
       "std         2.456529       2.813501       1.532080       3.825485   \n",
       "min        -5.519697     -42.147898     -23.496714     -43.557242   \n",
       "25%        -0.685276      -0.934655      -0.971244      -0.892838   \n",
       "50%         0.285916      -0.148289      -0.388440      -0.083415   \n",
       "75%         1.384394       0.579607       0.296348       0.493810   \n",
       "max        16.715537      34.099309      22.529298      36.877368   \n",
       "\n",
       "                  V8             V9      ...                  V20  \\\n",
       "count  147586.000000  147586.000000      ...        147586.000000   \n",
       "mean        0.093502      -0.450655      ...             0.065634   \n",
       "std         3.017389       1.735221      ...             0.922374   \n",
       "min       -73.216718     -13.434066      ...           -28.009635   \n",
       "25%        -0.209479      -1.026896      ...            -0.206396   \n",
       "50%         0.057332      -0.201091      ...            -0.039046   \n",
       "75%         0.459822       0.478908      ...             0.215385   \n",
       "max        20.007208      15.594995      ...            39.420904   \n",
       "\n",
       "                 V21            V22            V23            V24  \\\n",
       "count  147586.000000  147586.000000  147586.000000  147586.000000   \n",
       "mean        0.112510       0.002233      -0.010763      -0.019136   \n",
       "std         1.715664       0.900441       0.894272       0.590721   \n",
       "min       -34.830382     -10.933144     -30.269720      -2.822684   \n",
       "25%        -0.215443      -0.545816      -0.182292      -0.372216   \n",
       "50%         0.012646       0.005741      -0.016927       0.028828   \n",
       "75%         0.278251       0.539630       0.161528       0.410870   \n",
       "max        27.202839      10.503090      19.228169       4.022866   \n",
       "\n",
       "                 V25            V26            V27            V28  \\\n",
       "count  147586.000000  147586.000000  147586.000000  147586.000000   \n",
       "mean        0.007926       0.010054       0.029891       0.015904   \n",
       "std         0.580118       0.478784       0.681384       0.376441   \n",
       "min        -7.495741      -2.534330     -22.565679     -11.710896   \n",
       "25%        -0.317991      -0.314087      -0.069208      -0.054008   \n",
       "50%         0.030500      -0.039680       0.014370       0.017171   \n",
       "75%         0.368708       0.272505       0.169662       0.111651   \n",
       "max         7.519589       3.220178      12.152401      22.620072   \n",
       "\n",
       "              Amount  \n",
       "count  147586.000000  \n",
       "mean       93.021534  \n",
       "std       248.840715  \n",
       "min         0.000000  \n",
       "25%         3.790000  \n",
       "50%        20.000000  \n",
       "75%        84.000000  \n",
       "max     19656.530000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale features so they're all of comparable varience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = train_features.columns.values\n",
    "\n",
    "for col_name in cols:\n",
    "    avg, dev = frame[col_name].mean(), frame[col_name].std()\n",
    "    train_features.loc[:, col_name] = (train_features[col_name] - avg) / dev\n",
    "    train_features.loc[:, col_name] = (train_features[col_name] - avg) / dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "trainX = train_features.as_matrix()\n",
    "testX = test_features.as_matrix()\n",
    "validX = validation_features.as_matrix()\n",
    "\n",
    "trainY = np.reshape(train_labels.as_matrix(), (-1, 1))\n",
    "testY = np.reshape(test_labels.as_matrix(), (-1, 1))\n",
    "validY = np.reshape(validation_labels.as_matrix(), (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# layer size configuration\n",
    "input_nodes = len(trainX[0])\n",
    "hidden_layer_1 = 200\n",
    "hidden_layer_2 = 50\n",
    "hidden_layer_3 = 13\n",
    "output_nodes = 1\n",
    "dropout_keep_percentage = 0.75\n",
    "learning_rate = 0.01\n",
    "training_epochs = 1000\n",
    "display_step = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x_inputs = tf.placeholder(tf.float32, [None, input_nodes], name=\"x_inputs\")\n",
    "y_outputs = tf.placeholder(tf.float32,[None,1], name=\"y_outputs\")\n",
    "keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "\n",
    "weights1 = tf.Variable(tf.truncated_normal([input_nodes, hidden_layer_1], stddev=0.1))\n",
    "bias1 = tf.Variable(tf.zeros([hidden_layer_1]))\n",
    "hidden1 = tf.nn.relu(tf.matmul(x_inputs, weights1) + bias1)\n",
    "\n",
    "weights2 = tf.Variable(tf.truncated_normal([hidden_layer_1, hidden_layer_2], stddev=0.1))\n",
    "bias2 = tf.Variable(tf.zeros([hidden_layer_2]))\n",
    "hidden2 = tf.nn.relu(tf.matmul(hidden1, weights2) + bias2)\n",
    "\n",
    "weights3 = tf.Variable(tf.truncated_normal([hidden_layer_2, hidden_layer_3], stddev=0.1))\n",
    "bias3 = tf.Variable(tf.zeros([hidden_layer_3]))\n",
    "hidden3 = tf.nn.relu(tf.matmul(hidden2, weights3) + bias3)\n",
    "hidden3 = tf.nn.dropout(hidden3, keep_prob)\n",
    "\n",
    "output_weights = tf.Variable(tf.truncated_normal([hidden_layer_3, output_nodes], stddev=0.1))\n",
    "output_bias = tf.Variable(tf.zeros([output_nodes]))\n",
    "output = tf.nn.sigmoid(tf.matmul(hidden3, output_weights) + output_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.square(output - y_outputs))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "correct_prediction = tf.equal(tf.round(output), tf.round(y_outputs))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-65-80f4a80570a7>:1: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "TRAINING: 0.818736\n",
      "COST: 0.206296\n",
      "TEST: [0.99826115]\n",
      "epoch:  1\n",
      "epoch:  2\n",
      "epoch:  3\n",
      "epoch:  4\n",
      "epoch:  5\n",
      "epoch:  6\n",
      "epoch:  7\n",
      "epoch:  8\n",
      "epoch:  9\n",
      "epoch:  10\n",
      "epoch:  11\n",
      "epoch:  12\n",
      "epoch:  13\n",
      "epoch:  14\n",
      "epoch:  15\n",
      "epoch:  16\n",
      "epoch:  17\n",
      "epoch:  18\n",
      "epoch:  19\n",
      "epoch:  20\n",
      "epoch:  21\n",
      "epoch:  22\n",
      "epoch:  23\n",
      "epoch:  24\n",
      "epoch:  25\n",
      "epoch:  26\n",
      "epoch:  27\n",
      "epoch:  28\n",
      "epoch:  29\n",
      "epoch:  30\n",
      "epoch:  31\n",
      "epoch:  32\n",
      "epoch:  33\n",
      "epoch:  34\n",
      "epoch:  35\n",
      "epoch:  36\n",
      "epoch:  37\n",
      "epoch:  38\n",
      "epoch:  39\n",
      "epoch:  40\n",
      "epoch:  41\n",
      "epoch:  42\n",
      "epoch:  43\n",
      "epoch:  44\n",
      "epoch:  45\n",
      "epoch:  46\n",
      "epoch:  47\n",
      "epoch:  48\n",
      "epoch:  49\n",
      "epoch:  50\n",
      "epoch:  51\n",
      "epoch:  52\n",
      "epoch:  53\n",
      "epoch:  54\n",
      "epoch:  55\n",
      "epoch:  56\n",
      "epoch:  57\n",
      "epoch:  58\n",
      "epoch:  59\n",
      "epoch:  60\n",
      "epoch:  61\n",
      "epoch:  62\n",
      "epoch:  63\n",
      "epoch:  64\n",
      "epoch:  65\n",
      "epoch:  66\n",
      "epoch:  67\n",
      "epoch:  68\n",
      "epoch:  69\n",
      "epoch:  70\n",
      "epoch:  71\n",
      "epoch:  72\n",
      "epoch:  73\n",
      "epoch:  74\n",
      "epoch:  75\n",
      "epoch:  76\n",
      "epoch:  77\n",
      "epoch:  78\n",
      "epoch:  79\n",
      "epoch:  80\n",
      "epoch:  81\n",
      "epoch:  82\n",
      "epoch:  83\n",
      "epoch:  84\n",
      "epoch:  85\n",
      "epoch:  86\n",
      "epoch:  87\n",
      "epoch:  88\n",
      "epoch:  89\n",
      "epoch:  90\n",
      "epoch:  91\n",
      "epoch:  92\n",
      "epoch:  93\n",
      "epoch:  94\n",
      "epoch:  95\n",
      "epoch:  96\n",
      "epoch:  97\n",
      "epoch:  98\n",
      "epoch:  99\n",
      "epoch:  100\n",
      "TRAINING: 0.818736\n",
      "COST: 0.173696\n",
      "TEST: [0.99826115]\n",
      "epoch:  101\n",
      "epoch:  102\n",
      "epoch:  103\n",
      "epoch:  104\n",
      "epoch:  105\n",
      "epoch:  106\n",
      "epoch:  107\n",
      "epoch:  108\n",
      "epoch:  109\n",
      "epoch:  110\n",
      "epoch:  111\n",
      "epoch:  112\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-68942913b7a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_inputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_outputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdropout_keep_percentage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_inputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_outputs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ethan/anaconda/envs/dlnd/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ethan/anaconda/envs/dlnd/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ethan/anaconda/envs/dlnd/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/Users/ethan/anaconda/envs/dlnd/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ethan/anaconda/envs/dlnd/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('epoch: ', end=\" \")\n",
    "for i in range(training_epochs):  \n",
    "    print(i, '...', end=\" \")\n",
    "    sess.run([optimizer], feed_dict={x_inputs: trainX, y_outputs: trainY, keep_prob: dropout_keep_percentage})\n",
    "    if (i) % display_step == 0:\n",
    "        train_acc, train_cost = sess.run([accuracy, cost], feed_dict={x_inputs: trainX, y_outputs: trainY, keep_prob: 1.0})\n",
    "        test_acc = sess.run([accuracy], feed_dict={x_inputs: testX, y_outputs: testY, keep_prob: 1.0})\n",
    "        print(\"TRAINING:\", train_acc)\n",
    "        print(\"COST:\", train_cost)\n",
    "        print(\"TEST:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
